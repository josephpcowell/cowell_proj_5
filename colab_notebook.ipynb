{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Google Colab: Notebook for Finetuning GPT-2\n",
    "In order to finetune GPT-2 quickly, I used Google Colab and it's ability to source a GPU.  \n",
    "This notebook was produced with heavy reference to a notebook from [Max Woolf](https://minimaxir.com/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "# !pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "# Google Colab has some libraries pre-installed, but it's necessary to install gpt-2-simple for this notebook to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "# Running this cell displays the active GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.download_gpt2(model_name=\"124M\")\n",
    "# This cell downloads the necessary components to run the GPT-2 model\n",
    "# 124M is the smallest pre-trained GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.mount_gdrive()\n",
    "# Mounting your Google Drive allows easy access to Google Drive files and saving the finetuned GPT-2 model to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"lennon.txt\"\n",
    "# Specify the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=300,\n",
    "              restore_from='fresh',\n",
    "              run_name='lennon2',\n",
    "              print_every=10,\n",
    "              sample_every=150,\n",
    "              save_every=300,\n",
    "              overwrite=True\n",
    "              )\n",
    "# Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_to_gdrive(run_name='lennon2')\n",
    "# Save your fine-tuned model to Google Drive"
   ]
  },
  {
   "source": [
    "I ran this notebook to create a different fine-tuned model for each Beatle, as well as, all of The Beatles for my final implementation.  \n",
    "I messed around with steps to observe how the model changes with extra fine-tuning. Unfortunately, our dataset isn't too large, so overfitting happened quickly, thus the low number of steps to fine-tune this specific model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}